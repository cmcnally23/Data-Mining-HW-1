---
title: "Data Mining and Statistical Learning Homework #1"
output: pdf_document
---
# 1)  Data visualization: Flights at ABIA
```{r}
library(tidyverse)
library(ggplot2)
setwd('~/Dropbox/My Mac (Colin’s MacBook Pro)/Downloads/data-mining')
ABIA <- read.csv("~/Dropbox/My Mac (Colin’s MacBook Pro)/Downloads/data-mining/ABIA.csv")

#Changing NA Delay Results to O#
new_ABIA=ABIA%>%
  mutate_all(~replace(., is.na(.), 0))
View(new_ABIA)

#Beginning to Work the Data#
month_delays=new_ABIA%>%
  mutate(total_delay=CarrierDelay+WeatherDelay+NASDelay+SecurityDelay+LateAircraftDelay,depart_hour=CRSDepTime%/%100,month_names=month.name[Month])%>%
  filter(Origin=='AUS')%>%
  group_by(month_names,depart_hour)%>%
  select(month_names,depart_hour,total_delay)%>%
  summarize(count=n(),sum_delays=sum(total_delay), avg_delay=sum_delays/count)
View(month_delays)
```
```{r}
#Creating the Graph#
ggplot(month_delays)+
  geom_col(aes(x=depart_hour,y=avg_delay))+
  facet_wrap(~factor(month_names,levels=c('January','February','March','April','May','June','July','August','September','October','November','December')))+
  xlab('Expected Departure Hour')+
  ylab('Average Delay for a Flight (min)')+
  labs(
    title='Average Length of Delay Each Month for Each Hour of Flights Leaving Austin'
  )
```
For me there is nothing worse than a flight delay. When on a flight the level of annoyance I have for a delay greatly outweighs any semblance of utility I gain from an early or on-time flight. So I wanted to know what were the worst times of day to expect delays in any given month when leaving ABIA. And that is what these graphs are showing you. Peak delays out of ABIA occur when you would expect them like around Christmas and during Summer Vacation. So do not book flights out of Austin in the late afternoon in July!
# 2) Wrangling the Billboard Top 100

```{r}
library(tidyverse)
library(ggplot2)
library(rmarkdown)
setwd('~/Dropbox/My Mac (Colin’s MacBook Pro)/Downloads/data-mining')
billboard <- read.csv("billboard.csv")

#Part A of Question 2 Data Mining#
best_10=billboard%>%
  group_by(performer,song)%>%
  summarize(count=n())%>%
  select(performer,song,count)%>%
  arrange(desc(count))%>%
  head(10)

best_10

#Part B of Question 2 Data Mining#
musical_diversity=billboard%>% 
  filter(year>1958 & year<2021)%>%
  group_by(year,song_id)%>%
  summarize(count=n())%>%
  arrange(desc(count))

musical_diversity

actual_diversity=musical_diversity%>%
  group_by(year)%>%
  summarize(count=n())%>%
  arrange(desc(count))

actual_diversity  
```
```{r}
#Creating a Graph for Diversity Statistics#
ggplot(actual_diversity)+
  geom_line(aes(x=year,y=count))+
  ylim(1,1000)+
  xlab('Year')+
  ylab('Unique Songs')+
  labs(
    title='Song Diversity by Year'
  )
```
```{r}
#Part C of Question 2 Data Mining#
preliminary_hit=billboard%>% 
  group_by(song, performer)%>%
  summarize(count=n())%>%
  filter(count>=10)%>%
  arrange(desc(count))

preliminary_hit

ten_week_hit=preliminary_hit%>%
  group_by(performer)%>%
  summarize(count=n())%>%
  filter(count>=30)%>%
  arrange(desc(count))

ten_week_hit
```
```{r}
#Creating the Graph for Part C of Question 2#
ggplot(ten_week_hit)+
  geom_col(aes(fct_reorder(performer,
               count),
               count))+
  xlab('Artists')+
  ylab('# of Ten Week Hits')+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  labs(
    title='Artists with 30 or More Ten Week Hits',
  )
```
This chart shows all Artists with over 30 Ten Week Hit. As well it shows that the most Ten Week Hits by any Artist is Elton John. The only Artists with over 40 Ten Week Hits are Kenny Chesney, Madonna and Elton John
# 3) Wrangling the Olympics

```{r}
setwd('~/Dropbox/My Mac (Colin’s MacBook Pro)/Downloads/data-mining')
olympics_top20 <- read.csv("olympics_top20.csv")

#Part A of Question 3 Data Mining#
women_height=olympics_top20%>%
  filter(sex=='F')%>%
  group_by(event)%>%
  select(event, height)%>%
  summarize(women_height_95pct=quantile(height,probs=0.95,na.rm=TRUE))%>%
  arrange(desc(women_height_95pct))

women_height

#Part B of Question 3 Data Mining#
womens_height_variability=olympics_top20%>%
  filter(sex=='F')%>%
  group_by(event)%>%
  select(event, height)%>%
  summarize(height_variability=sd(height))%>%
  arrange(desc(height_variability))

View(womens_height_variability)

#Part C of Question Data Mining#
swimmers_age=olympics_top20%>%
  filter(sport=='Swimming')%>%
  group_by(year,sex)%>%
  summarize(mean_age=mean(age))


View(swimmers_age) 
```
```{r}
#Graph for Part C#
ggplot(swimmers_age)+
  geom_line(aes(x=year,y=mean_age,color=sex))+
  xlab('Olympic Years')+
  ylab("Average Swimmer's Age")+
  labs(
    title="Average Swimmer's Age at Each Olympics By Sex",
  )
```
The average age of olypmic swimmers over time has steadily increased since 1900.The large spike for the age of men in the early 1900's is most likely due to World War 1.Women tend to be younger swimmers at the olympics than men, but both have steadily increased in average age since 1975 onwards.
# 4) K-nearest neighbors
```{r}
library(caret)
library(rsample)
library(modelr)
library(foreach)
library(parallel)
setwd('~/Dropbox/My Mac (Colin’s MacBook Pro)/Downloads/data-mining')
sclass <- read_csv("sclass.csv")

#Creating Table for Trim Level 350#
set.seed(9)
trim350=sclass%>%
  filter(trim==350)%>%
  select(price,mileage)

View(trim350)

ggplot(data=trim350)+
  geom_point(mapping=aes(x=mileage,y=price))

#Making the split#
trim350_split= initial_split(trim350, prop=0.8)
trim350_train= training(trim350_split)
trim350_test= testing(trim350_split)

#Models#
lm1= lm(price~mileage,data=trim350_train)
lm2=lm(price~poly(mileage,2),data=trim350_train)

#KNN Regression at K=2#

trim350_knn2=knnreg(price~mileage,data=trim350_train)
rmse(trim350_knn2,trim350_test)

#More KNN tests#
trim350_knn10=knnreg(price~mileage,data=trim350_train,k=10)
rmse(trim350_knn10,trim350_test)

trim350_knn25=knnreg(price~mileage, data=trim350_train,k=25)
rmse(trim350_knn25,trim350_test)

#Attach Predictions to the Test Data#
trim350_test=trim350_test%>%
  mutate(price350_predk2=predict(trim350_knn2,trim350_test))

#Graph the Predictions for K=2#
p_test350k2=ggplot(data=trim350_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test350k2+geom_line(aes(x=mileage,y=price350_predk2),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 350, K=2'
  )
```

```{r}
#Other Graphs for Different K Values#
trim350_test=trim350_test%>%
  mutate(price350_predk10=predict(trim350_knn10,trim350_test))

trim350_test=trim350_test%>%
  mutate(price350_predk25=predict(trim350_knn25,trim350_test))

p_test350k10=ggplot(data=trim350_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test350k10+geom_line(aes(x=mileage,y=price350_predk10),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 350, K=10'
  )

p_test350k25=ggplot(data=trim350_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test350k25+geom_line(aes(x=mileage,y=price350_predk25),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 350, K=25'
  )
```
```{r}
#Finding the Perfect Value of K for 350 Trim#
rmse_out350=foreach(i=1:75, .combine='c') %do% {
  knn_model350= knnreg(price~mileage, data=trim350_train, k=i)
  modelr::rmse(knn_model350,trim350_test)
}
rmse_out350
k=c(1:75)
bestk_350=data.frame(k,rmse_out350)
ggplot(bestk_350)+
  geom_line(aes(x=k,y=rmse_out350))+
  geom_vline(xintercept=15, color='red')+
  xlab('# of K Nearest Neighbors')+
  ylab('Root Mean Square Deviation')+
  labs(
    title="Root Mean Square Deviation for Each #K Nearest Neighbor:
                                          Trim 350"
  )
```
```{r}

trim350_knn15=knnreg(price~mileage,data=trim350_train,k=15)
rmse(trim350_knn15,trim350_test)

trim350_test=trim350_test%>%
  mutate(price350_predk15=predict(trim350_knn15,trim350_test))

p_test350k15=ggplot(data=trim350_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test350k15+geom_line(aes(x=mileage,y=price350_predk15),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 350, K=15'
  )
```
```{r}
#Creating Table for Trim Level 6 AMG#
trim65AMG=sclass%>%
  filter(trim=='65 AMG')%>%
  select(price,mileage)

View(trim65AMG)

#Making the split#
trim65AMG_split= initial_split(trim65AMG, prop=0.8)
trim65AMG_train= training(trim65AMG_split)
trim65AMG_test= testing(trim65AMG_split)

#Models#
lm1= lm(price~mileage,data=trim65AMG_train)
lm2=lm(price~poly(mileage,2),data=trim65AMG_train)

#KNN Regression at K=2#

trim65AMG_knn2=knnreg(price~mileage,data=trim65AMG_train)
rmse(trim65AMG_knn2,trim65AMG_test)

#More KNN tests#
trim65AMG_knn10=knnreg(price~mileage,data=trim65AMG_train,k=10)
rmse(trim65AMG_knn10,trim65AMG_test)

trim65AMG_knn25=knnreg(price~mileage, data=trim65AMG_train,k=25)
rmse(trim65AMG_knn25,trim65AMG_test)

#Attach Predictions to the Test Data#
trim65AMG_test=trim65AMG_test%>%
  mutate(price65AMG_predk2=predict(trim65AMG_knn2,trim65AMG_test))
```
```{r}
#Graph the Predictions for K=2#
p_test65AMGk2=ggplot(data=trim65AMG_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test65AMGk2+geom_line(aes(x=mileage,y=price65AMG_predk2),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 65AMG, K=2'
  )
```
```{r}
#Other Graphs for Different K Values to See Differences#
trim65AMG_test=trim65AMG_test%>%
  mutate(price65AMG_predk10=predict(trim65AMG_knn10,trim65AMG_test))

trim65AMG_test=trim65AMG_test%>%
  mutate(price65AMG_predk25=predict(trim65AMG_knn25,trim65AMG_test))

p_test65AMGk10=ggplot(data=trim65AMG_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test65AMGk10+geom_line(aes(x=mileage,y=price65AMG_predk10),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 65AMG, K=10'
  )

p_test65AMGk25=ggplot(data=trim65AMG_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test65AMGk25+geom_line(aes(x=mileage,y=price65AMG_predk25),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 65AMG, K=25'
  )
```
```{r}
#Finding the Perfect Value for K for Trim 65AMG#
rmse_out65AMG=foreach(i=1:75, .combine='c') %do% {
  knn_model65AMG= knnreg(price~mileage, data=trim65AMG_train, k=i)
  modelr::rmse(knn_model65AMG,trim65AMG_test)
}
rmse_out65AMG
k=c(1:75)
bestk_65AMG=data.frame(k,rmse_out65AMG)
ggplot(bestk_65AMG)+
  geom_line(aes(x=k,y=rmse_out65AMG))+
  geom_vline(xintercept=6, color='red')+
  xlab('# of K Nearest Neighbors')+
  ylab('Root Mean Square Deviation')+
  labs(
    title="Root Mean Square Deviation for Each #K Nearest Neighbor:
                                          Trim 65AMG"
  )
```
```{r}
#Fitting Predictions to Real Data for BEst Value of K Trim 65AMG
trim65AMG_knn6=knnreg(price~mileage,data=trim65AMG_train,k=6)
rmse(trim65AMG_knn6,trim65AMG_test)

trim65AMG_test=trim65AMG_test%>%
  mutate(price65AMG_predk6=predict(trim65AMG_knn6,trim65AMG_test))

p_test65AMGk6=ggplot(data=trim65AMG_test)+
  geom_point(mapping=aes(x=mileage,y=price),alpha=0.2)
p_test65AMGk6+geom_line(aes(x=mileage,y=price65AMG_predk6),color='red',size=1.5)+
  xlab('Mileage')+
  ylab('Price')+
  labs(
    title='K Nearest Neighbors Prediction for Price
    Based on Mileage for an S-Class Trim 65AMG, K=6'
  )
```
The trim level 350 has a larger value for K Nearest Neighbors compared to 65AMG. I believe this is because the trim level 350 has about 100 more observations than 65AMG. This means that the 350 trim is more likely to have more variance. To compensate for the problem of variance using a larger K allows for it to compare across larger spreads of data.